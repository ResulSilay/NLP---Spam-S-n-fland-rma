{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - Spam Sınıflandırma v1.0.0.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "n3EB5sUAdEbp",
        "csr1O1hHVoYN",
        "UxgO2PWhbydK",
        "vqCvahqALho6",
        "mGt6cPhWcGmU",
        "cNqnOo0HeFMd",
        "BAj1w-MkeWN4",
        "DpVaQvCWertZ",
        "FM1Fof_QfWvF"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srzvDIuncX9g",
        "colab_type": "text"
      },
      "source": [
        "# **NLP - Spam Sınıflandırması**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlx10cK93iwl",
        "colab_type": "text"
      },
      "source": [
        "## **Giriş**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TdFSCkgq2xLU"
      },
      "source": [
        "Bu çalışma, NLP - Doğal Dil İşleme tekniği ile spam mesajlarının sınıflandırılarak tahmin edilmesi üzerine gerçekleştirilen bir örnektir.\n",
        "\n",
        "Dataset: 'SMS Spam Collection Dataset' \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3EB5sUAdEbp",
        "colab_type": "text"
      },
      "source": [
        "## **Kurulum**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3eCZL86coQs",
        "colab_type": "text"
      },
      "source": [
        "### Kütüphaneler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RARoe2AgcqwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from termcolor import colored\n",
        "from tensorflow import keras\n",
        "layers = keras.layers\n",
        "models = keras.models\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKnGnnYxc1bk",
        "colab_type": "text"
      },
      "source": [
        "### Veri Seti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGZDJEeRc8LY",
        "colab_type": "code",
        "outputId": "8bc524cc-077c-4e2a-e93c-7e1b1d8fd747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = pd.read_csv(\"spam.csv\", encoding = \"ISO-8859-1\")\n",
        "dataFrame = pd.DataFrame(data)\n",
        "\n",
        "columns = [\"state\", \"context\"]\n",
        "dataFrame = dataFrame[columns]\n",
        "\n",
        "print(\"Dataset Size: \", dataFrame.size)\n",
        "dataFrame.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Size:  11144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  state                                            context\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csr1O1hHVoYN",
        "colab_type": "text"
      },
      "source": [
        "## **Veri Önişlemler**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9uP1L30V9qD",
        "colab_type": "text"
      },
      "source": [
        "### Temizleme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNqAW5DhGbkR",
        "colab_type": "code",
        "outputId": "e6437055-1617-490d-a5a4-4b6bde841433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataFrame = dataFrame.dropna(how='any',axis=0)\n",
        "print(dataFrame.size)\n",
        "dataFrame.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  state                                            context\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE9EhJPbWYDg",
        "colab_type": "text"
      },
      "source": [
        "### Değiştirme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY-AmpcrSkIU",
        "colab_type": "code",
        "outputId": "f1996f89-1a05-4f6b-ea93-57cbf0277684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "dataFrame['state'] = dataFrame['state'].replace(['ham'],0)\n",
        "dataFrame['state'] = dataFrame['state'].replace(['spam'],1)\n",
        "dataFrame.head()\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndataFrame['state'] = dataFrame['state'].replace(['ham'],0)\\ndataFrame['state'] = dataFrame['state'].replace(['spam'],1)\\ndataFrame.head()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxgO2PWhbydK",
        "colab_type": "text"
      },
      "source": [
        "## **NLP Önişlemler**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqCvahqALho6",
        "colab_type": "text"
      },
      "source": [
        "### Noisy Entity Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieviwkUnLh7C",
        "colab_type": "code",
        "outputId": "25f38618-0810-4af4-8365-f8d82f88a7b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"String Punctuation: \",string.punctuation)\n",
        "dataFrame.context = dataFrame.context.str.translate(str.maketrans('', '', string.punctuation))\n",
        "dataFrame.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "String Punctuation:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point crazy Available only in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor U c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  state                                            context\n",
              "0   ham  Go until jurong point crazy Available only in ...\n",
              "1   ham                            Ok lar Joking wif u oni\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham        U dun say so early hor U c already then say\n",
              "4   ham  Nah I dont think he goes to usf he lives aroun..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSE-poBtTjLg",
        "colab_type": "text"
      },
      "source": [
        "### Lowercasing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb8rATZyGl4g",
        "colab_type": "code",
        "outputId": "c8b5c92d-437d-42c3-c594-cc403b9b985c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataFrame.context = dataFrame.context.str.lower()\n",
        "dataFrame.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  state                                            context\n",
              "0   ham  go until jurong point crazy available only in ...\n",
              "1   ham                            ok lar joking wif u oni\n",
              "2  spam  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3   ham        u dun say so early hor u c already then say\n",
              "4   ham  nah i dont think he goes to usf he lives aroun..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0ev8bI61nee",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2idisOf1rXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words = 100\n",
        "tokenize = keras.preprocessing.text.Tokenizer(num_words=max_words, char_level=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGt6cPhWcGmU",
        "colab_type": "text"
      },
      "source": [
        "## **Veri Seti İşlemleri**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3arP8wfLdvXZ",
        "colab_type": "text"
      },
      "source": [
        "### Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhgiSPSqdX__",
        "colab_type": "code",
        "outputId": "d1a5b49a-3c97-4e1a-8f1e-fede2754fd33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_size = int(len(dataFrame) * 0.3)\n",
        "print (\"Train size: %d\" % train_size)\n",
        "print (\"Test size: %d\" % (len(data) - train_size))\n",
        "\n",
        "def train_test_split(dataFrame, train_size):\n",
        "    train = dataFrame[:train_size]\n",
        "    test = dataFrame[train_size:]\n",
        "    return train, test\n",
        "  \n",
        "train_y, test_y = train_test_split(dataFrame['state'], train_size)\n",
        "train_x, test_x = train_test_split(dataFrame['context'], train_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 1671\n",
            "Test size: 3901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxGTjER6dkc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenize.fit_on_texts(train_x)\n",
        "x_train = tokenize.texts_to_matrix(train_x)\n",
        "x_test = tokenize.texts_to_matrix(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSByYTbqdsnr",
        "colab_type": "text"
      },
      "source": [
        "### Label (Etiketleme) & Kategorilendirme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Lsibcqd40o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_y)\n",
        "y_train = encoder.transform(train_y)\n",
        "y_test = encoder.transform(test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgcrFdfEeC5C",
        "colab_type": "code",
        "outputId": "f081528c-d56e-4f9e-d3ed-d5d15edf0343",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_classes = np.max(y_train) + 1\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\"\"\"\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nprint('x_train shape:', x_train.shape)\\nprint('x_test shape:', x_test.shape)\\nprint('y_train shape:', y_train.shape)\\nprint('y_test shape:', y_test.shape)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SICrfUXKfEJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_labels = encoder.classes_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNqnOo0HeFMd",
        "colab_type": "text"
      },
      "source": [
        "## **Eğitim/Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MzAF6JFea4J",
        "colab_type": "text"
      },
      "source": [
        "Modelin eğitilmesi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAj1w-MkeWN4",
        "colab_type": "text"
      },
      "source": [
        "### Modelin Oluşturulması"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSTJqRjtehdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32   #batch_size 2 ve katları olacak şekilde belirlenmelidir. 64 - 128 ....\n",
        "epochs = 10       #veri setinin model üzerinden geçme sayısı. 1 epoch tüm veri setinin 1 kez model üzerinden geçmesi anlamına gelmektedir.\n",
        "drop_ratio = 0.5  #düşme oranı.\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, input_shape=(max_words,)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(drop_ratio))\n",
        "model.add(layers.Dense(100))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dense(num_classes))\n",
        "model.add(layers.Activation('softmax')) #softmax aktivasyon fonksiyonu özniteliklerin önceliklerini belirlenmesi özelliğini barındırır.\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=0,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9tQJn3Mel8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpVaQvCWertZ",
        "colab_type": "text"
      },
      "source": [
        "### Değerlendirme\n",
        "Modelin test verisi ile metrik ölçümlerinin yapılması."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aQFUrjge4aM",
        "colab_type": "code",
        "outputId": "4a2ca148-da98-41e4-bcba-0e5ebdde1926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "predict = model.predict(x_train)\n",
        "\n",
        "score = model.evaluate(x_test, y_test,batch_size=batch_size, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9618\n",
            "Test loss: 0.18275538086891174\n",
            "Test accuracy: 0.9618046879768372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM1Fof_QfWvF",
        "colab_type": "text"
      },
      "source": [
        "## **Tahmin**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsK8HN9vfbI-",
        "colab_type": "text"
      },
      "source": [
        "Modele dışarıdan girilen veriler üzerinde tahminde bulunulması."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-lAy-uqfeiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(title,actual):\n",
        "  temp = tokenize.texts_to_matrix([title])       \n",
        "  prediction = model.predict(np.array([temp[0]]))\n",
        "  acc = prediction[0][np.argmax(prediction)]\n",
        "  predicted_label = text_labels[np.argmax(prediction)]\n",
        "  \n",
        "  if(acc>0.80):\n",
        "    print(colored(\"Data          : \" + title, 'green'))\n",
        "    print(colored(\"Gerçek durum  : \" + actual, 'green'))\n",
        "    print(colored(\"Tahmin basari : %\" + str(acc), 'green'))  \n",
        "    print(colored(\"Tahmin durum  : \" + str(predicted_label), 'green'))  \n",
        "    print(\"\")\n",
        "  else:\n",
        "    print(colored(\"Data          : \" + title, 'red'))\n",
        "    print(colored(\"Gerçek durum  : \" + actual, 'red'))\n",
        "    print(colored(\"Tahmin basari : %\" + str(acc), 'red'))  \n",
        "    print(colored(\"Tahmin durum  : \" + str(predicted_label), 'red'))  \n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqJa1CBSfgOZ",
        "colab_type": "code",
        "outputId": "d0a8481b-a14e-4157-f65d-bd8156f68f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "print(\"Etiketler: \",text_labels)\n",
        "print(\"\")\n",
        "\n",
        "print(\"-Tahmin Edilmesi Beklenen Veriler-\")  \n",
        "print(\"--------------------------------\")\n",
        "predict('We will give you $1,000 for sending an e-mail to your friends.  AB Mailing, Inc. is proud to anounce the start of a new contest.  Each day until January, 31 1999, one lucky Internet or AOL user who forwards our advertisement to their friends will be randomly picked to receive $1,000! You could be the winner!','Spam')\n",
        "predict('Have you finished your paperwork for Kaken and writing academic articles? If you have some free time in the near future, I want to meet you and explain to you our next project.','Normal e-Posta')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Etiketler:  ['ham' 'spam']\n",
            "\n",
            "-Tahmin Edilmesi Beklenen Veriler-\n",
            "--------------------------------\n",
            "\u001b[32mData          : We will give you $1,000 for sending an e-mail to your friends.  AB Mailing, Inc. is proud to anounce the start of a new contest.  Each day until January, 31 1999, one lucky Internet or AOL user who forwards our advertisement to their friends will be randomly picked to receive $1,000! You could be the winner!\u001b[0m\n",
            "\u001b[32mGerçek durum  : Spam\u001b[0m\n",
            "\u001b[32mTahmin basari : %0.9954035\u001b[0m\n",
            "\u001b[32mTahmin durum  : spam\u001b[0m\n",
            "\n",
            "\u001b[32mData          : Have you finished your paperwork for Kaken and writing academic articles? If you have some free time in the near future, I want to meet you and explain to you our next project.\u001b[0m\n",
            "\u001b[32mGerçek durum  : Normal e-Posta\u001b[0m\n",
            "\u001b[32mTahmin basari : %0.9029755\u001b[0m\n",
            "\u001b[32mTahmin durum  : ham\u001b[0m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}